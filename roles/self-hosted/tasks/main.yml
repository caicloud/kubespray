# Ensure COS namespaces exist
- name: Ensure {{ self_hosted_config_dir }} directory exist
  file:
    name: "{{ self_hosted_config_dir }}"
    state: directory

- name: Generate COS namespaces yaml
  template:
    src: cos-system-ns.yml.j2
    dest: "{{ self_hosted_config_dir }}/cos-system-ns.yml"
  when:
    - cos_running_namespaces not in ["default", "kube-system", "kube-node-lease", "kube-public"]

- name: Create COS namespaces
  kube:
    name: "{{ item.name }}"
    kubectl: "{{ bin_dir }}/kubectl"
    resource: "{{ item.type }}"
    filename: "{{ self_hosted_config_dir }}/{{ item.file }}"
    state: "{{ item.state }}"
  with_items:
    - name: "{{ cos_running_namespaces }}"
      type: namespaces
      file: cos-system-ns.yml
      state: latest
  when:
    - cos_running_namespaces not in ["default", "kube-system", "kube-node-lease", "kube-public"]
    - inventory_hostname in groups['kube-master'][0]

# Add label on master node
- name: Add label on master node
  shell: |
    kubectl label node {{ inventory_hostname }} {{ item }}
  with_items:
    - node-role.release.containeros.dev/primary-master=true
    - node-role.release.containeros.dev/primary-etcd=true
  register: label_status
  until: label_status.rc == 0
  retries: 30
  delay: 10
  when:
    - inventory_hostname in groups['kube-master'][0]

# Ensure self-hosted config dir exist
- name: Ensure self-hosted config dir exist
  file:
    path: "{{ self_hosted_config_dir }}"
    state: directory
    owner: root
    group: root
    mode: 0o755

# Read ssh certs and create secret
- name: Read ssh private key
  slurp:
    src: "{{ ansible_ssh_private_key_file }}"
  register: ssh_key_id_rsa
  delegate_to: localhost

- name: Read ssh public key
  slurp:
    src: "{{ansible_ssh_private_key_file}}.pub"
  register: ssh_key_id_rsa_pub
  delegate_to: localhost

- name: Generate ssh key secret
  template:
    src: ssh_secret.yml.j2
    dest: "{{ self_hosted_config_dir }}/ssh_secret.yml"
  when:
    - inventory_hostname in groups['kube-master'][0]

- name: Create secret for ssh identification
  shell: |
    kubectl apply -f {{ self_hosted_config_dir }}/ssh_secret.yml
  when:
    - inventory_hostname in groups['kube-master'][0]

- name: Copy image registry cert to master node
  copy:
    src: "{{ image_registry_signed_certificate }}"
    dest: "{{ kube_config_dir }}/registry-ca.crt"
  when: image_registry_ca_self_sign

- name: Create secret for image registry ca cert
  shell: |
    kubectl -n {{ cos_running_namespaces }} delete secret registry-ca-cert || true && \
    kubectl -n {{ cos_running_namespaces }} create secret generic registry-ca-cert --from-file={{ kube_config_dir }}/registry-ca.crt
  when:
    - image_registry_ca_self_sign
    - inventory_hostname in groups['kube-master'][0]

- name: Create empty secret for image registry ca cert
  shell: |
    kubectl -n {{ cos_running_namespaces }} delete secret registry-ca-cert || true && \
    kubectl -n {{ cos_running_namespaces }} create secret generic registry-ca-cert
  when:
    - not image_registry_ca_self_sign
    - inventory_hostname in groups['kube-master'][0]

# Fetch the kubeconfig file from cluster master node
- name: Fetch kubeconfig from master
  fetch:
    src: "/root/.kube/config"
    dest: "{{ item }}"
    flat: true
    validate_checksum: no
  with_items:
    - "{{ local_kubeconfig_file }}"
    - "{{ local_vip_kubeconfig_file }}"
  when:
    - inventory_hostname in groups['kube-master'][0]

- name: Modify kubeconfig when cluster_vip is defined
  shell: |
    sed -i "s#{{ hostvars[groups['kube-master'][0]]['ansible_host'] }}#{{ cluster_vip }}#g" {{ local_vip_kubeconfig_file }}
  delegate_to: localhost
  when:
    - cluster_vip is defined
    - inventory_hostname in groups['kube-master'][0]

- name: Read kubeconfig file
  include_vars:
    file: "{{ local_vip_kubeconfig_file }}"
  register: kubeConfigFile
  when:
    - inventory_hostname in groups['kube-master'][0]

# Create system-info, cluster-config-info configmap
- name: Generate system-info config map
  template:
    src: "{{ item }}.j2"
    dest: "{{ kube_config_dir }}/{{ item }}"
  with_items:
    - system-info-cm.yml
    - cluster-config-info-cm.yml
  when:
    - deploy_control_cluster|bool
    - inventory_hostname in groups['kube-master'][0]

- name: Apply cm system-info to cluster
  kube:
    name: "{{ item.name }}"
    kubectl: "{{ bin_dir }}/kubectl"
    resource: "{{ item.type }}"
    filename: "{{ kube_config_dir }}/{{ item.file }}"
    state: "latest"
  with_items:
    - name: system-info
      type: cm
      file: system-info-cm.yml
    - name: cluster-config-info
      type: cm
      file: cluster-config-info-cm.yml
  when:
    - deploy_control_cluster|bool
    - inventory_hostname in groups['kube-master'][0]

# Create cluster-info configmap
- name: Generate cluster-info config map
  template:
    src: "{{ item }}.j2"
    dest: "{{ kube_config_dir }}/{{ item }}"
  with_items:
    - cluster-info-cm.yml
  when:
    - inventory_hostname in groups['kube-master'][0]

- name: Apply cm cluster-info to cluster
  kube:
    name: "{{ item.name }}"
    kubectl: "{{ bin_dir }}/kubectl"
    resource: "{{ item.type }}"
    filename: "{{ kube_config_dir }}/{{ item.file }}"
    state: "latest"
  with_items:
    - name: cluster-info
      type: cm
      file: cluster-info-cm.yml
  when:
    - inventory_hostname in groups['kube-master'][0]

# Create VIP
- name: Create VIP
  import_tasks: create-vip.yml
  when:
    - not deploy_control_cluster|bool
    - groups['kube-master'] | length > 1
    - inventory_hostname in groups['kube-master'][0]
    - cluster_vip != ""

- name: Generate kubeconfig file base64 code
  shell: |
    cat {{ local_vip_kubeconfig_file }} | base64 | tr -d "\n"
  delegate_to: localhost
  register: local_kubeconfig_base64

- name: Generate cluster crd
  template:
    src: "{{ item }}.j2"
    dest: "{{ local_config_path }}/{{ item }}"
  with_items:
    - cluster-crd-patch.yml
  delegate_to: localhost
  when:
    - not deploy_control_cluster|bool
    - inventory_hostname in groups['kube-master'][0]

# TODO: Modify kube.py, support kubectl patch
- name: Upgrade {{ cluster_identity_name }} cluster cr message
  shell: |
    kubectl patch cluster {{ cluster_identity_name }} --type merge -p "$(cat {{ local_config_path }}/{{ item }})"
  with_items:
    - cluster-crd-patch.yml
  delegate_to: localhost
  when:
    - not deploy_control_cluster|bool
    - inventory_hostname in groups['kube-master'][0]

- name: Create etcd tls secret
  shell: |
    kubectl -n {{ cos_running_namespaces }} delete secret etcd-tls-secrets || true && \
    kubectl -n {{ cos_running_namespaces }} create secret generic etcd-tls-secrets \
      --from-file=main-etcd-ca.pem={{ etcd_cert_dir }}/ca.pem \
      --from-file=main-etcd-client.crt={{ etcd_cert_dir }}/admin-{{ inventory_hostname }}.pem \
      --from-file=main-etcd-client.key={{ etcd_cert_dir }}/admin-{{ inventory_hostname }}-key.pem \
      --from-file=event-etcd-ca.pem={{ etcd_cert_dir }}/ca.pem \
      --from-file=event-etcd-client.crt={{ etcd_cert_dir }}/admin-{{ inventory_hostname }}.pem \
      --from-file=event-etcd-client.key={{ etcd_cert_dir }}/admin-{{ inventory_hostname }}-key.pem
  when:
    - inventory_hostname in groups['kube-master'][0]

# TODO: remove it when component have self rbac
- name: Create default service account
  shell: |
    kubectl create clusterrolebinding permissive-binding \
    --clusterrole=cluster-admin \
    --user=admin \
    --user=kubelet \
    --group=system:serviceaccounts
  when:
    - inventory_hostname in groups['kube-master'][0]
  ignore_errors: true
